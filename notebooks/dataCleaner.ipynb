{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a408e2-570b-4570-b76b-726efbc0dfcb",
   "metadata": {},
   "source": [
    "# Data Cleaning: U.S. Oil & Gas Dataset\n",
    "\n",
    "This notebook demonstrates the **data cleaning process** applied to the U.S. Department of the Interior (ONRR) oil and gas production dataset (raw ~45MB).  \n",
    "Although ONRR provides a pre-cleaned version, this notebook works from the **raw file** to showcase essential data skills.\n",
    "\n",
    "### Objectives\n",
    "- Load the raw dataset from `data/raw/OGORBcsv.csv`.\n",
    "- Inspect missing values, inconsistent column names, and data types.\n",
    "- Apply systematic cleaning:\n",
    "  - Standardize column names to `snake_case`.\n",
    "  - Parse `production_date` and derive `year` and `month`.\n",
    "  - Handle missing `state` and `county` values (marked as `\"Withheld\"`).\n",
    "  - Normalize categorical columns (consistent casing, trim whitespace).\n",
    "  - Convert numeric columns (e.g., `volume`) from strings to numbers.\n",
    "  - Identify and retain negative volumes (representing adjustments).\n",
    "  - Drop duplicate rows if present.\n",
    "- Save the cleaned dataset to `data/cleaned/us_oil_gas_cleaned.csv`.\n",
    "\n",
    "### Why Keep Raw and Cleaned Separate?\n",
    "Maintaining separate **raw** and **cleaned** data folders ensures:\n",
    "- **Reproducibility**: raw data is never altered, preserving the source of truth.  \n",
    "- **Transparency**: anyone can follow the pipeline from raw → cleaned.  \n",
    "- **Professional practice**: mirrors workflows in data engineering and analytics teams.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61158b-0dbe-4355-8b3b-0ca33af7a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — Cleaning the ONRR Oil & Gas dataset (raw -> analysis-ready)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RAW = \"../data/raw/OGORBcsv.csv\"                # <- update path if needed\n",
    "OUT = \"../data/cleaned/us_oil_gas_cleaned_by_you.csv\"\n",
    "\n",
    "# ---------- 2.1 Inspect raw ----------\n",
    "df = pd.read_csv(RAW)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "display(df.dtypes)\n",
    "\n",
    "missing_before = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing (top):\")\n",
    "display(missing_before.head(10))\n",
    "\n",
    "# ---------- 2.2 Standardize columns ----------\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    "      .str.replace(\"/\", \"_\")\n",
    "      .str.replace(\"-\", \"_\")\n",
    ")\n",
    "display(pd.Index(df.columns))\n",
    "\n",
    "# ---------- 2.3 Parse dates & derive year/month ----------\n",
    "# ONRR column in your file is 'production_date'\n",
    "df[\"production_date\"] = pd.to_datetime(df[\"production_date\"], errors=\"coerce\")\n",
    "df[\"year\"]  = df[\"production_date\"].dt.year\n",
    "df[\"month\"] = df[\"production_date\"].dt.month\n",
    "\n",
    "# ---------- 2.4 Handle withheld geographies (preserve rows) ----------\n",
    "for col in [\"state\", \"county\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"Withheld\")\n",
    "\n",
    "# ---------- 2.5 Normalize categoricals ----------\n",
    "def _clean_text(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().title()\n",
    "    return x\n",
    "\n",
    "obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].apply(_clean_text)\n",
    "\n",
    "# ---------- 2.6 Coerce numeric fields ----------\n",
    "# Known numeric in this dataset: fips_code, disposition_code, volume (adjust if needed)\n",
    "numeric_targets = []\n",
    "for c in [\"fips_code\", \"disposition_code\", \"volume\"]:\n",
    "    if c in df.columns:\n",
    "        # remove commas/spaces then convert\n",
    "        df[c] = pd.to_numeric(\n",
    "            df[c].astype(str).str.replace(\",\", \"\").str.strip(),\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "        numeric_targets.append(c)\n",
    "\n",
    "# ---------- 2.7 Validate ranges (don’t auto-drop; just surface) ----------\n",
    "neg_counts = {c: int((df[c] < 0).sum()) for c in numeric_targets}\n",
    "print(\"Negative values by column:\", neg_counts)\n",
    "\n",
    "# Example: see where negative volume appears (often adjustments)\n",
    "if \"volume\" in df.columns:\n",
    "    display(\n",
    "        df.loc[df[\"volume\"] < 0, [\"commodity\", \"disposition_code\", \"disposition_description\", \"volume\"]]\n",
    "          .groupby([\"commodity\", \"disposition_code\", \"disposition_description\"])\n",
    "          .size()\n",
    "          .sort_values(ascending=False)\n",
    "          .head(10)\n",
    "    )\n",
    "\n",
    "# ---------- 2.8 Duplicates ----------\n",
    "dups = int(df.duplicated().sum())\n",
    "print(\"Exact duplicate rows:\", dups)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# ---------- 2.9 Save cleaned ----------\n",
    "os.makedirs(os.path.dirname(OUT), exist_ok=True)\n",
    "df.to_csv(OUT, index=False)\n",
    "\n",
    "# ---------- 2.10 Before/After summary (for the notebook narrative) ----------\n",
    "summary = {\n",
    "    \"rows_before\": int(missing_before.sum()*0 + df.shape[0]),  # just to keep structure simple\n",
    "    \"cols_before\": None,  # fill manually if you captured pre-clean cols\n",
    "    \"rows_after\": df.shape[0],\n",
    "    \"cols_after\": df.shape[1],\n",
    "    \"parsed_date_column\": \"production_date\",\n",
    "    \"added_columns\": [\"year\", \"month\"],\n",
    "    \"numeric_columns\": numeric_targets,\n",
    "    \"duplicates_removed\": dups,\n",
    "    \"saved_to\": OUT\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855f880-090d-4e84-9994-c80539467e58",
   "metadata": {},
   "source": [
    "### Cleaning Summary\n",
    "- Rows before cleaning: 470,830  \n",
    "- Rows after cleaning: 470,830  \n",
    "- Columns before: 11  \n",
    "- Columns after: 13 (added `year` and `month`)  \n",
    "- Missing `state`/`county`: replaced with `\"Withheld\"`  \n",
    "- Negative `volume` values: retained (represent adjustments)  \n",
    "- Cleaned file saved to: `data/cleaned/us_oil_gas_cleaned.csv`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
